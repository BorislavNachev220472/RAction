{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import trimesh.exchange.binvox as binvox\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import trimesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Autoencoder with Conv3D layers.\n",
    "\n",
    "The input is size is 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2DVAE(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(CNN2DVAE, self).__init__()\n",
    "\n",
    "        reshape = 8  # Adjusted based on downsampling\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1),  # [32, 128, 128]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),  # [64, 64, 64]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # [128, 32, 32]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),  # [256, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),  # [512, 8, 8]\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc_mu = nn.Linear(512 * reshape * reshape, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(512 * reshape * reshape, latent_dim)\n",
    "        self.fc_decode = nn.Linear(latent_dim, 512 * reshape * reshape)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),  # [256, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # [128, 32, 32]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # [64, 64, 64]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),  # [32, 128, 128]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1),  # [1, 256, 256]\n",
    "            nn.Sigmoid()  # Output between 0 and 1 for binary image\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.reshape(x.size(0), -1)  # Flatten\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        x = self.fc_decode(z)\n",
    "        x = x.reshape(x.size(0), 512, 8, 8)  # Reshape to convolutional shape\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "# Loss function remains the same\n",
    "def vae_loss(recon_x, target_x, mu, logvar):\n",
    "    recon_loss = nn.functional.binary_cross_entropy(recon_x, target_x, reduction='sum')\n",
    "    # KL Divergence Loss\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the model, set loss function and optimizer.\n",
    "\n",
    "Put the model on to the device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the VoxelDataset for dataset loading. It does loads in the object from obj, converts it to voxel_grid and pads the grid to shape (64, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_array_if_large(arr):\n",
    "    shape = arr.shape\n",
    "    \n",
    "    if any(dim > 256 for dim in shape):\n",
    "        resized_arr = arr[:256, :256, :256]\n",
    "    else:\n",
    "        resized_arr = arr\n",
    "\n",
    "    return resized_arr\n",
    "\n",
    "def get_voxel_matrix(mesh):\n",
    "    voxel = mesh.voxelized(pitch=1.0/64)\n",
    "    voxel_matrix = voxel.matrix.astype(np.float32) \n",
    "    \n",
    "    target_shape = [256, 256, 256]\n",
    "\n",
    "    voxel_matrix = resize_array_if_large(voxel_matrix)\n",
    "    \n",
    "    padded_matrix = np.zeros((256,256,256))\n",
    "    offset_x = 0\n",
    "    offset_y = 0\n",
    "    offset_z = 0\n",
    "    \n",
    "    # Place the original matrix in the padded matrix\n",
    "    padded_matrix[0 + offset_x : offset_x + voxel_matrix.shape[0] ,\n",
    "                0  + offset_y : offset_y + voxel_matrix.shape[1],\n",
    "                0 + offset_z : offset_z + voxel_matrix.shape[2]] = voxel_matrix\n",
    "    \n",
    "    padded_voxelized = trimesh.voxel.VoxelGrid(padded_matrix)\n",
    "    voxel_matrix = padded_voxelized.matrix.astype(np.float32) \n",
    "    return voxel_matrix\n",
    "\n",
    "def create_view(voxel_matrix):\n",
    "    axial_grid = [voxel_matrix[:, :, i] for i in range(voxel_matrix.shape[2])]\n",
    "    coronal_grid = [voxel_matrix[:, i, :] for i in range(voxel_matrix.shape[1])]\n",
    "    sagittal_grid = [voxel_matrix[i, :, :] for i in range(voxel_matrix.shape[0])]\n",
    "    axial_grid = np.array(axial_grid)\n",
    "    coronal_grid = np.array(coronal_grid)\n",
    "    sagittal_grid = np.array(sagittal_grid)\n",
    "    \n",
    "    first_view = np.zeros((256,256,256,3))\n",
    "    first_view[..., 0] = axial_grid\n",
    "    first_view[..., 1] = sagittal_grid\n",
    "    first_view[..., 2] = coronal_grid\n",
    "    return first_view\n",
    "\n",
    "def transform_mesh(mesh):\n",
    "    voxel_matrix = get_voxel_matrix(mesh)\n",
    "    view = create_view(voxel_matrix)\n",
    "    return view\n",
    "\n",
    "def get_slices(obj):\n",
    "    axial_slice = obj[:, :, 0]       # 256 x 256\n",
    "    sagittal_slice = obj[:, 0, :]    # 256 x 256\n",
    "    coronal_slice = obj[0, :, :]     # 256 x 256\n",
    "\n",
    "    combined_slice = torch.stack([\n",
    "        torch.tensor(axial_slice, dtype=torch.float32),\n",
    "        torch.tensor(sagittal_slice, dtype=torch.float32),\n",
    "        torch.tensor(coronal_slice, dtype=torch.float32)\n",
    "    ], dim=0)  # Stack along a new dimension (3, 256, 256)\n",
    "    \n",
    "    return combined_slice\n",
    "\n",
    "class Dataset2D(Dataset):\n",
    "    def __init__(self, train_path, label_path):\n",
    "        self.label_dir = label_path\n",
    "        self.train_dir = train_path\n",
    "\n",
    "        self.label_list = os.listdir(self.label_dir)\n",
    "        self.obj_list = os.listdir(self.label_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.obj_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        train_obj = trimesh.load_mesh(self.train_dir + '/' + self.obj_list[idx])\n",
    "        label_obj = trimesh.load_mesh(self.label_dir + '/' + self.label_list[idx])\n",
    "\n",
    "        train_obj = transform_mesh(train_obj)\n",
    "        label_obj = transform_mesh(label_obj)\n",
    "\n",
    "        train_obj = get_slices(train_obj)\n",
    "        label_obj = get_slices(label_obj)\n",
    "        \n",
    "        print(train_obj.shape)\n",
    "        print(label_obj.shape)\n",
    "        \n",
    "\n",
    "        return train_obj, label_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class Dataset2D(Dataset):\\n    def __init__(self, data_folder, label_folder):\\n        # Load list of files for both data and labels\\n        self.data_files = sorted([os.path.join(data_folder, f) for f in os.listdir(data_folder)])\\n        self.label_files = sorted([os.path.join(label_folder, f) for f in os.listdir(label_folder)])\\n\\n\\n        assert len(self.data_files) == len(self.label_files), \"Mismatch between number of data and label files.\"\\n\\n        self.num_slices_per_file = 256\\n        self.total_slices = len(self.data_files) * self.num_slices_per_file\\n\\n    def __len__(self):\\n        return self.total_slices\\n\\n    def __getitem__(self, idx):\\n        file_idx = idx // self.num_slices_per_file\\n        slice_idx = idx % self.num_slices_per_file\\n\\n        data_file = self.data_files[file_idx]\\n        label_file = self.label_files[file_idx]\\n        \\n        data_array = np.load(data_file)\\n        label_array = np.load(label_file)\\n\\n        data_slice = data_array[:, slice_idx, :, :]  \\n        label_slice = label_array[:, slice_idx, :, :]  \\n\\n        # Convert to PyTorch tensors\\n        data_tensor = torch.tensor(data_slice, dtype=torch.float32)\\n        label_tensor = torch.tensor(label_slice, dtype=torch.float32)\\n\\n        return data_tensor, label_tensor\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class Dataset2D(Dataset):\n",
    "    def __init__(self, data_folder, label_folder):\n",
    "        # Load list of files for both data and labels\n",
    "        self.data_files = sorted([os.path.join(data_folder, f) for f in os.listdir(data_folder)])\n",
    "        self.label_files = sorted([os.path.join(label_folder, f) for f in os.listdir(label_folder)])\n",
    "\n",
    "\n",
    "        assert len(self.data_files) == len(self.label_files), \"Mismatch between number of data and label files.\"\n",
    "\n",
    "        self.num_slices_per_file = 256\n",
    "        self.total_slices = len(self.data_files) * self.num_slices_per_file\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_slices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_idx = idx // self.num_slices_per_file\n",
    "        slice_idx = idx % self.num_slices_per_file\n",
    "\n",
    "        data_file = self.data_files[file_idx]\n",
    "        label_file = self.label_files[file_idx]\n",
    "        \n",
    "        data_array = np.load(data_file)\n",
    "        label_array = np.load(label_file)\n",
    "\n",
    "        data_slice = data_array[:, slice_idx, :, :]  \n",
    "        label_slice = label_array[:, slice_idx, :, :]  \n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        data_tensor = torch.tensor(data_slice, dtype=torch.float32)\n",
    "        label_tensor = torch.tensor(label_slice, dtype=torch.float32)\n",
    "\n",
    "        return data_tensor, label_tensor\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input the data, set voxel resolution and set dataloader. \n",
    "\n",
    "Batch size of 1 because only 1 data object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model and optimizer\n",
    "latent_dim = 512\n",
    "model = CNN2DVAE(latent_dim=latent_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# Create dataset and dataloader for training\n",
    "voxel_dataset = Dataset2D(\"dataset_3d/train/train\", \"dataset_3d/ground_truth/ground_truth\")\n",
    "#voxel_dataloader = DataLoader(voxel_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 6779\n",
      "Validation set size: 1695\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# Example: 80% training, 20% validation\n",
    "train_size = int(0.8 * len(voxel_dataset))\n",
    "val_size = len(voxel_dataset) - train_size\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "train_dataset, val_dataset = random_split(voxel_dataset, [train_size, val_size])\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")\n",
    "\n",
    "# Create DataLoaders for both sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "def train_vae_3d(model, train_loader, val_loader, optimizer, epochs=20, device='cuda', checkpoint_path='vae_checkpoint_2D.pth'):\n",
    "    # Check if checkpoint exists and load it\n",
    "    start_epoch = 0\n",
    "    best_val_loss = float('inf')\n",
    "    model.to(device)  # Move the model to the correct device\n",
    "    print(f\"Training on {device}, model now on {device}\")\n",
    "\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)  # Ensure checkpoint is loaded on the correct device\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1  # Start training from the next epoch\n",
    "        best_val_loss = checkpoint['best_loss']\n",
    "        print(f\"Loaded checkpoint from epoch {checkpoint['epoch']}, with best loss {best_val_loss:.4f}\")\n",
    "\n",
    "    model.train()\n",
    "    print(f\"Starting training from epoch {start_epoch}\")\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        \n",
    "        # Track time for each epoch\n",
    "        start_time = time.time()\n",
    "        train_loss = 0\n",
    "        \n",
    "        # Training loop\n",
    "        model.train()  # Set model to training mode\n",
    "        for input_batch, expected_batch in train_loader:\n",
    "            print(input_batch.shape)\n",
    "            \n",
    "\n",
    "\n",
    "            input_batch = input_batch.to(device)\n",
    "            expected_batch = expected_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            input_batch = input_batch.permute(0, 3, 1, 2) \n",
    "            recon_batch, mu, logvar = model(input_batch) \n",
    "            expected_batch = expected_batch.permute(0, 3, 1, 2)\n",
    "\n",
    "            loss = vae_loss(recon_batch, expected_batch, mu, logvar)  \n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Validation loop\n",
    "        val_loss = 0\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        with torch.no_grad():  # No need to compute gradients for validation\n",
    "            for input_batch, expected_batch in val_loader:\n",
    "                input_batch = input_batch.to(device)\n",
    "                expected_batch = expected_batch.to(device)\n",
    "\n",
    "                recon_batch, mu, logvar = model(input_batch)  # Forward pass\n",
    "                loss = vae_loss(recon_batch, expected_batch, mu, logvar)  # Compute loss\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "\n",
    "        # Track time at the end of the epoch\n",
    "        end_time = time.time()\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "        # Save model checkpoint if validation loss is the best\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_loss': best_val_loss\n",
    "            }, checkpoint_path)\n",
    "            print(f\"Checkpoint saved at epoch {epoch+1}, with validation loss {best_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on mps, model now on mps\n",
      "Starting training from epoch 0\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n",
      "torch.Size([3, 256, 256, 3])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_vae_3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 30\u001b[0m, in \u001b[0;36mtrain_vae_3d\u001b[0;34m(model, train_loader, val_loader, optimizer, epochs, device, checkpoint_path)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()  \u001b[38;5;66;03m# Set model to training mode\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_batch, expected_batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(input_batch\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     35\u001b[0m     input_batch \u001b[38;5;241m=\u001b[39m input_batch\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/specifix-rl/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/specifix-rl/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/specifix-rl/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/specifix-rl/lib/python3.9/site-packages/torch/utils/data/dataset.py:419\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/specifix-rl/lib/python3.9/site-packages/torch/utils/data/dataset.py:419\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[0;32mIn[3], line 81\u001b[0m, in \u001b[0;36mDataset2D.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     78\u001b[0m train_obj \u001b[38;5;241m=\u001b[39m trimesh\u001b[38;5;241m.\u001b[39mload_mesh(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj_list[idx])\n\u001b[1;32m     79\u001b[0m label_obj \u001b[38;5;241m=\u001b[39m trimesh\u001b[38;5;241m.\u001b[39mload_mesh(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_list[idx])\n\u001b[0;32m---> 81\u001b[0m train_obj \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_mesh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m label_obj \u001b[38;5;241m=\u001b[39m transform_mesh(label_obj)\n\u001b[1;32m     84\u001b[0m train_obj \u001b[38;5;241m=\u001b[39m get_slices(train_obj)\n",
      "Cell \u001b[0;32mIn[3], line 48\u001b[0m, in \u001b[0;36mtransform_mesh\u001b[0;34m(mesh)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform_mesh\u001b[39m(mesh):\n\u001b[0;32m---> 48\u001b[0m     voxel_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mget_voxel_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmesh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     view \u001b[38;5;241m=\u001b[39m create_view(voxel_matrix)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m view\n",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m, in \u001b[0;36mget_voxel_matrix\u001b[0;34m(mesh)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_voxel_matrix\u001b[39m(mesh):\n\u001b[0;32m---> 12\u001b[0m     voxel \u001b[38;5;241m=\u001b[39m \u001b[43mmesh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvoxelized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpitch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     voxel_matrix \u001b[38;5;241m=\u001b[39m voxel\u001b[38;5;241m.\u001b[39mmatrix\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \n\u001b[1;32m     15\u001b[0m     target_shape \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/specifix-rl/lib/python3.9/site-packages/trimesh/base.py:2539\u001b[0m, in \u001b[0;36mTrimesh.voxelized\u001b[0;34m(self, pitch, method, **kwargs)\u001b[0m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;124;03mReturn a VoxelGrid object representing the current mesh\u001b[39;00m\n\u001b[1;32m   2523\u001b[0m \u001b[38;5;124;03mdiscretized into voxels at the specified pitch\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2535\u001b[0m \u001b[38;5;124;03m  Representing the current mesh\u001b[39;00m\n\u001b[1;32m   2536\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2537\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvoxel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m creation\n\u001b[0;32m-> 2539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvoxelize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpitch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpitch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/specifix-rl/lib/python3.9/site-packages/trimesh/voxel/creation.py:287\u001b[0m, in \u001b[0;36mvoxelize\u001b[0;34m(mesh, pitch, method, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvoxelize\u001b[39m(mesh, pitch, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubdivide\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    267\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m    Voxelize the given mesh using the specified implementation.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m    A VoxelGrid instance.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvoxelizers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpitch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpitch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/specifix-rl/lib/python3.9/site-packages/trimesh/util.py:2281\u001b[0m, in \u001b[0;36mFunctionRegistry.__call__\u001b[0;34m(self, key, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/specifix-rl/lib/python3.9/site-packages/trimesh/constants.py:151\u001b[0m, in \u001b[0;36mlog_time.<locals>.timed\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtimed\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    150\u001b[0m     tic \u001b[38;5;241m=\u001b[39m now()\n\u001b[0;32m--> 151\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m executed in \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m, method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, now() \u001b[38;5;241m-\u001b[39m tic)\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/specifix-rl/lib/python3.9/site-packages/trimesh/voxel/creation.py:41\u001b[0m, in \u001b[0;36mvoxelize_subdivide\u001b[0;34m(mesh, pitch, max_iter, edge_factor)\u001b[0m\n\u001b[1;32m     37\u001b[0m     max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(np\u001b[38;5;241m.\u001b[39mlog2(longest_edge \u001b[38;5;241m/\u001b[39m max_edge))), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# get the same mesh sudivided so every edge is shorter\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# than a factor of our pitch\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m v, _f, _idx \u001b[38;5;241m=\u001b[39m \u001b[43mremesh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdivide_to_size\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmesh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvertices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmesh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfaces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_edge\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_edge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     43\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# convert the vertices to their voxel grid position\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Provided edge_factor > 1 and max_iter is large enough, this is\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# sufficient to preserve 6-connectivity at the level of voxels.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m hit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(v \u001b[38;5;241m/\u001b[39m pitch)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/specifix-rl/lib/python3.9/site-packages/trimesh/remesh.py:166\u001b[0m, in \u001b[0;36msubdivide_to_size\u001b[0;34m(vertices, faces, max_edge, max_iter, return_index)\u001b[0m\n\u001b[1;32m    162\u001b[0m edge_length \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    163\u001b[0m     np\u001b[38;5;241m.\u001b[39mdiff(current_vertices[current_faces[:, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m]], :\u001b[38;5;241m3\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    164\u001b[0m )\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# check edge length against maximum\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m too_long \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43medge_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_edge\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# faces that are OK\u001b[39;00m\n\u001b[1;32m    168\u001b[0m face_ok \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mtoo_long\n",
      "File \u001b[0;32m/opt/anaconda3/envs/specifix-rl/lib/python3.9/site-packages/numpy/core/_methods.py:58\u001b[0m, in \u001b[0;36m_any\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_any\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_any\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_any(a, axis, dtype, out, keepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_vae_3d(model, train_loader, val_loader, optimizer, epochs=2000, device='mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Specifix-Reinforcement",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
