{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(10800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import trimesh\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import trimesh.exchange.binvox as binvox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Autoencoder with Conv3D layers.\n",
    "\n",
    "The input is size is 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN3DVAE(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(CNN3DVAE, self).__init__()\n",
    "\n",
    "        reshape = 4\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(1, 32, kernel_size=4, stride=2, padding=1),  # [32, 32, 32, 32]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(32, 64, kernel_size=4, stride=2, padding=1),  # [64, 16, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(64, 128, kernel_size=4, stride=2, padding=1),  # [128, 8, 8, 8]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(128, 256, kernel_size=4, stride=2, padding=1),  # [256, 4, 4, 4]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(256, 512, kernel_size=4, stride=2, padding=1),  # [256, 4, 4, 4]\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc_mu = nn.Linear(512 * reshape * reshape * reshape, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(512 * reshape * reshape * reshape, latent_dim)\n",
    "        self.fc_decode = nn.Linear(latent_dim, 512 * reshape * reshape * reshape)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(512, 256, kernel_size=4, stride=2, padding=1),  # [128, 8, 8, 8]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(256, 128, kernel_size=4, stride=2, padding=1),  # [128, 8, 8, 8]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(128, 64, kernel_size=4, stride=2, padding=1),  # [64, 16, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(64, 32, kernel_size=4, stride=2, padding=1),  # [32, 32, 32, 32]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(32, 1, kernel_size=4, stride=2, padding=1),  # [1, 64, 64, 64]\n",
    "            nn.Sigmoid()  # Output between 0 and 1\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        x = self.fc_decode(z)\n",
    "        x = x.view(x.size(0), 512, 4, 4, 4)  # Reshape to convolutional shape\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "\n",
    "# Loss function\n",
    "def vae_loss(recon_x, target_x, mu, logvar):\n",
    "    recon_loss = nn.functional.binary_cross_entropy(recon_x, target_x, reduction='sum')\n",
    "    # KL Divergence Loss\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + kl_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the model, set loss function and optimizer.\n",
    "\n",
    "Put the model on to the device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the VoxelDataset for dataset loading. It does loads in the object from obj, converts it to voxel_grid and pads the grid to shape (64, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoxelDataset(Dataset):\n",
    "    def __init__(self, data_path, labels_path):\n",
    "        self.data_path = data_path\n",
    "        self.labels_path = labels_path\n",
    "\n",
    "        self.data_files = os.listdir(data_path)\n",
    "        self.label_files = os.listdir(labels_path)\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    def load_pre_processed_voxel(self, file_path):\n",
    "\n",
    "        with open(file_path, 'rb') as f:\n",
    "            voxel_grid = binvox.load_binvox(f)\n",
    "        \n",
    "        return voxel_grid\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        \n",
    "        train_mesh_file = os.path.join(self.data_path, self.data_files[idx])\n",
    "        train_voxel = self.load_pre_processed_voxel(train_mesh_file)\n",
    "        train_voxel_matrix = train_voxel.matrix.astype(np.float32) \n",
    "\n",
    "        label_mesh_file = os.path.join(self.labels_path, self.label_files[idx])\n",
    "        label_voxel = self.load_pre_processed_voxel(label_mesh_file)\n",
    "        label_voxel_matrix = label_voxel.matrix.astype(np.float32)\n",
    "\n",
    "        input_voxel = np.expand_dims(train_voxel_matrix, axis=0)\n",
    "        target_voxel = np.expand_dims(label_voxel_matrix, axis=0)\n",
    "\n",
    "\n",
    "        return torch.tensor(input_voxel), torch.tensor(target_voxel)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input the data, set voxel resolution and set dataloader. \n",
    "\n",
    "Batch size of 1 because only 1 data object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model and optimizer\n",
    "latent_dim = 512\n",
    "model = CNN3DVAE(latent_dim=latent_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# Create dataset and dataloader for training\n",
    "voxel_dataset = VoxelDataset(\"Data/train5/Pre-processed/128/train\", \"Data/train5/Pre-processed/128/labels\")\n",
    "#voxel_dataloader = DataLoader(voxel_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# Example: 80% training, 20% validation\n",
    "train_size = int(0.8 * len(voxel_dataset))\n",
    "val_size = len(voxel_dataset) - train_size\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "train_dataset, val_dataset = random_split(voxel_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for both sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "def train_vae_3d(model, train_loader, val_loader, optimizer, epochs=20, device='cuda', checkpoint_path='vae_checkpoint.pth'):\n",
    "    # Check if checkpoint exists and load it\n",
    "    start_epoch = 0\n",
    "    best_val_loss = float('inf')\n",
    "    model.to(device)  # Move the model to the correct device\n",
    "    print(f\"Training on {device}, model now on {device}\")\n",
    "\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)  # Ensure checkpoint is loaded on the correct device\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1  # Start training from the next epoch\n",
    "        best_val_loss = checkpoint['best_loss']\n",
    "        print(f\"Loaded checkpoint from epoch {checkpoint['epoch']}, with best loss {best_val_loss:.4f}\")\n",
    "\n",
    "    model.train()\n",
    "    print(f\"Starting training from epoch {start_epoch}\")\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        # Track time for each epoch\n",
    "        start_time = time.time()\n",
    "        train_loss = 0\n",
    "        \n",
    "        # Training loop\n",
    "        model.train()  # Set model to training mode\n",
    "        for input_batch, expected_batch in train_loader:\n",
    "\n",
    "            input_batch = input_batch.to(device)\n",
    "            expected_batch = expected_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = model(input_batch)  # Forward pass\n",
    "\n",
    "\n",
    "            loss = vae_loss(recon_batch, expected_batch, mu, logvar)  # Compute loss\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Validation loop\n",
    "        val_loss = 0\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        with torch.no_grad():  # No need to compute gradients for validation\n",
    "            for input_batch, expected_batch in val_loader:\n",
    "                input_batch = input_batch.to(device)\n",
    "                expected_batch = expected_batch.to(device)\n",
    "\n",
    "                recon_batch, mu, logvar = model(input_batch)  # Forward pass\n",
    "                loss = vae_loss(recon_batch, expected_batch, mu, logvar)  # Compute loss\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "\n",
    "        # Track time at the end of the epoch\n",
    "        end_time = time.time()\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "        # Save model checkpoint if validation loss is the best\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_loss': best_val_loss\n",
    "            }, checkpoint_path)\n",
    "            print(f\"Checkpoint saved at epoch {epoch+1}, with validation loss {best_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda, model now on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\AppData\\Local\\Temp\\ipykernel_26128\\2942685481.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)  # Ensure checkpoint is loaded on the correct device\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from epoch 0, with best loss 38703.2702\n",
      "Starting training from epoch 1\n"
     ]
    }
   ],
   "source": [
    "train_vae_3d(model, train_loader, val_loader, optimizer, epochs=2000, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loaded checkpoint from epoch 2, with best loss 81482.4339\n",
    "Starting training from epoch 3\n",
    "Epoch 4, Train Loss: 78760.3150, Val Loss: 78828.6544, Time: 110.61 seconds\n",
    "Checkpoint saved at epoch 4, with validation loss 78828.6544\n",
    "Epoch 5, Train Loss: 78374.0195, Val Loss: 78582.1556, Time: 109.58 seconds\n",
    "Checkpoint saved at epoch 5, with validation loss 78582.1556\n",
    "Epoch 6, Train Loss: 77333.7012, Val Loss: 77044.7628, Time: 107.79 seconds\n",
    "Checkpoint saved at epoch 6, with validation loss 77044.7628\n",
    "Epoch 7, Train Loss: 76398.3599, Val Loss: 77033.0401, Time: 107.53 seconds\n",
    "Checkpoint saved at epoch 7, with validation loss 77033.0401\n",
    "Epoch 8, Train Loss: 75108.3008, Val Loss: 74105.2728, Time: 107.97 seconds\n",
    "Checkpoint saved at epoch 8, with validation loss 74105.2728\n",
    "Epoch 9, Train Loss: 73875.8382, Val Loss: 74564.8534, Time: 107.26 seconds\n",
    "Epoch 10, Train Loss: 73709.9448, Val Loss: 72756.2539, Time: 107.31 seconds\n",
    "Checkpoint saved at epoch 10, with validation loss 72756.2539\n",
    "Epoch 11, Train Loss: 72947.6701, Val Loss: 73899.4487, Time: 107.45 seconds\n",
    "Epoch 12, Train Loss: 72084.1303, Val Loss: 72219.8246, Time: 107.40 seconds\n",
    "Checkpoint saved at epoch 12, with validation loss 72219.8246\n",
    "Epoch 13, Train Loss: 71603.3918, Val Loss: 71182.3434, Time: 111.30 seconds\n",
    "Checkpoint saved at epoch 13, with validation loss 71182.3434\n",
    "Epoch 14, Train Loss: 71557.7964, Val Loss: 71981.1636, Time: 113.69 seconds\n",
    "Epoch 15, Train Loss: 71426.3750, Val Loss: 70903.6943, Time: 113.50 seconds\n",
    "Checkpoint saved at epoch 15, with validation loss 70903.6943\n",
    "Epoch 16, Train Loss: 70913.7461, Val Loss: 70715.3565, Time: 111.35 seconds\n",
    "Checkpoint saved at epoch 16, with validation loss 70715.3565\n",
    "Epoch 17, Train Loss: 70652.2332, Val Loss: 71125.3929, Time: 110.15 seconds\n",
    "Epoch 18, Train Loss: 70184.2880, Val Loss: 69756.0963, Time: 110.55 seconds\n",
    "Checkpoint saved at epoch 18, with validation loss 69756.0963\n",
    "Epoch 19, Train Loss: 70230.5434, Val Loss: 69405.5184, Time: 112.12 seconds\n",
    "Checkpoint saved at epoch 19, with validation loss 69405.5184\n",
    "Epoch 20, Train Loss: 69758.8516, Val Loss: 72031.8733, Time: 112.99 seconds\n",
    "Epoch 21, Train Loss: 69550.8717, Val Loss: 69890.1854, Time: 111.46 seconds\n",
    "Epoch 22, Train Loss: 69617.5468, Val Loss: 71135.8658, Time: 111.18 seconds\n",
    "Epoch 23, Train Loss: 69368.2436, Val Loss: 68601.0923, Time: 111.74 seconds\n",
    "Checkpoint saved at epoch 23, with validation loss 68601.0923\n",
    "Epoch 24, Train Loss: 68895.7006, Val Loss: 68567.4258, Time: 110.98 seconds\n",
    "Checkpoint saved at epoch 24, with validation loss 68567.4258\n",
    "Epoch 25, Train Loss: 68823.1834, Val Loss: 68181.7952, Time: 112.11 seconds\n",
    "Checkpoint saved at epoch 25, with validation loss 68181.7952\n",
    "Epoch 26, Train Loss: 69036.1165, Val Loss: 69682.0627, Time: 114.03 seconds\n",
    "Epoch 27, Train Loss: 68734.5376, Val Loss: 68092.8073, Time: 110.79 seconds\n",
    "Checkpoint saved at epoch 27, with validation loss 68092.8073\n",
    "Epoch 28, Train Loss: 68322.9151, Val Loss: 68022.2327, Time: 110.74 seconds\n",
    "Checkpoint saved at epoch 28, with validation loss 68022.2327\n",
    "Epoch 29, Train Loss: 68399.0886, Val Loss: 68552.3808, Time: 107.57 seconds\n",
    "Epoch 30, Train Loss: 68623.9734, Val Loss: 68372.5990, Time: 112.72 seconds\n",
    "Epoch 31, Train Loss: 68390.2851, Val Loss: 70227.0090, Time: 109.74 seconds\n",
    "Epoch 32, Train Loss: 68243.8787, Val Loss: 67727.8196, Time: 108.38 seconds\n",
    "Checkpoint saved at epoch 32, with validation loss 67727.8196\n",
    "Epoch 33, Train Loss: 67820.6121, Val Loss: 68789.5640, Time: 109.06 seconds\n",
    "Epoch 34, Train Loss: 67856.4738, Val Loss: 67286.1321, Time: 108.65 seconds\n",
    "Checkpoint saved at epoch 34, with validation loss 67286.1321\n",
    "Epoch 35, Train Loss: 68019.6468, Val Loss: 68550.6108, Time: 109.48 seconds\n",
    "Epoch 36, Train Loss: 67811.4905, Val Loss: 72664.1964, Time: 109.53 seconds\n",
    "Epoch 37, Train Loss: 67780.5393, Val Loss: 67641.0478, Time: 109.29 seconds\n",
    "Epoch 38, Train Loss: 67641.5571, Val Loss: 66998.9193, Time: 110.17 seconds\n",
    "Checkpoint saved at epoch 38, with validation loss 66998.9193\n",
    "Epoch 39, Train Loss: 67849.5221, Val Loss: 67176.3940, Time: 109.53 seconds\n",
    "Epoch 40, Train Loss: 67861.7164, Val Loss: 67395.5032, Time: 108.60 seconds\n",
    "Epoch 41, Train Loss: 67428.7246, Val Loss: 67391.4132, Time: 110.91 seconds\n",
    "Epoch 42, Train Loss: 67550.3604, Val Loss: 67247.8164, Time: 113.49 seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Specifix-Reinforcement",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
